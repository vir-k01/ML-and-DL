{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Techsoc: Conditional Text Generation with GPT-2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9c5e0804cb9b473e89c91b359f0011db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4fa802271d304e3fa614632775ed525e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dff126491e7346cbbf4d18342507e120",
              "IPY_MODEL_da06e8cb1ade4df1bfb2eb2995e38e3e"
            ]
          }
        },
        "4fa802271d304e3fa614632775ed525e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dff126491e7346cbbf4d18342507e120": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c8f5c46185734d0c958473375d94627e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dbb5c284e3de4ccfa33d6f1cb99d946f"
          }
        },
        "da06e8cb1ade4df1bfb2eb2995e38e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d57e653cc7d241b6964fbe989ffa18ed",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [00:00&lt;00:00, 16.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_338d059d5ab3441c9473c45126af20d8"
          }
        },
        "c8f5c46185734d0c958473375d94627e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dbb5c284e3de4ccfa33d6f1cb99d946f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d57e653cc7d241b6964fbe989ffa18ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "338d059d5ab3441c9473c45126af20d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "731653a4f85642f0ae327e82a52c8fe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_80a473331aaf4ffe8408de10199d66bd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f6965a40dcd4436e817353a60f1a2634",
              "IPY_MODEL_921e29fff60749f1863a0e15cb2f641b"
            ]
          }
        },
        "80a473331aaf4ffe8408de10199d66bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6965a40dcd4436e817353a60f1a2634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_79b6fca8ae6a491787d5c4831a7a8fd0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2784d9076df84fb8bcdf9ccaa0006002"
          }
        },
        "921e29fff60749f1863a0e15cb2f641b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_44bbaf8ed01e491590071dc672dabd59",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 1.24MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61df7bbec4104f5a834ba7908365d450"
          }
        },
        "79b6fca8ae6a491787d5c4831a7a8fd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2784d9076df84fb8bcdf9ccaa0006002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44bbaf8ed01e491590071dc672dabd59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61df7bbec4104f5a834ba7908365d450": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58f398457e2a49028b746d2a0d64edbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d8ebe772fa22404ea9dcbb6f9f9acace",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_82d6217b4a2d41c68a908e8ece3989f4",
              "IPY_MODEL_e1d7741765b240158f4a7db20cf97ffb"
            ]
          }
        },
        "d8ebe772fa22404ea9dcbb6f9f9acace": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "82d6217b4a2d41c68a908e8ece3989f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b418411dac42484fb337066b4d08c284",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a2c0c506c904745a832f66065071267"
          }
        },
        "e1d7741765b240158f4a7db20cf97ffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_41662164888d43fa97db2e2c16768716",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:21&lt;00:00, 20.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a43f1849597c48968d197eb4c56c7bf6"
          }
        },
        "b418411dac42484fb337066b4d08c284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a2c0c506c904745a832f66065071267": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "41662164888d43fa97db2e2c16768716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a43f1849597c48968d197eb4c56c7bf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1d7fcc6fac943d3875fe40af6ee8752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e90d7967ba11430daab0c8c53acd932f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0402843310504b6e9979187c8da88fef",
              "IPY_MODEL_8e4eaf93b91342c48f74d2a4d8771f70"
            ]
          }
        },
        "e90d7967ba11430daab0c8c53acd932f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0402843310504b6e9979187c8da88fef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fa78f5fefa9a452a957055a9adf074e7",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355256,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355256,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9575371c8394b8586b3a69ae4d81ce5"
          }
        },
        "8e4eaf93b91342c48f74d2a4d8771f70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9b2a17e209a8400c855a6dd26d354ae4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.36M/1.36M [00:01&lt;00:00, 832kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ad35862b38e466299c793cb3f884490"
          }
        },
        "fa78f5fefa9a452a957055a9adf074e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9575371c8394b8586b3a69ae4d81ce5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b2a17e209a8400c855a6dd26d354ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ad35862b38e466299c793cb3f884490": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bf52ac19acea4364b11a06e98cf57759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3b2b89b308b7466180cb8f2a7ec5fc33",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0bccf6c3334748bbbe144b644877b7b2",
              "IPY_MODEL_2e8e788616114661b60af2b03b60cf61"
            ]
          }
        },
        "3b2b89b308b7466180cb8f2a7ec5fc33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0bccf6c3334748bbbe144b644877b7b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_98dd5b3c5ca24ae3bd309072af0d4f1f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 548118077,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 548118077,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40b8d871ad084c129c9ee8ed9f8b2591"
          }
        },
        "2e8e788616114661b60af2b03b60cf61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a1f177e8aa24408a8cc9d1fe40d81132",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 548M/548M [00:19&lt;00:00, 28.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a97962f638054388b653d1e30b58673a"
          }
        },
        "98dd5b3c5ca24ae3bd309072af0d4f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40b8d871ad084c129c9ee8ed9f8b2591": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1f177e8aa24408a8cc9d1fe40d81132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a97962f638054388b653d1e30b58673a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vir-k01/ML-and-DL/blob/main/Techsoc_Conditional_Text_Generation_with_GPT_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwRhz144Fknp"
      },
      "source": [
        "Related article: https://www.ivanlai.project-ds.net/post/conditional-text-generation-by-fine-tuning-gpt-2\n",
        "\n",
        "Training functions and utilities taken from the HuggingFace library. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSWYe3LMSP-b"
      },
      "source": [
        "### Install and import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f3CQg2yKB81",
        "outputId": "01fc6d57-6ea8-42af-8775-6117eab2633f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xk9lb9GmZuS",
        "outputId": "bbce88dd-f269-4520-c933-a9409b20ba49"
      },
      "source": [
        "\n",
        "%%time\n",
        "%%capture\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 48.7 ms, sys: 10.8 ms, total: 59.5 ms\n",
            "Wall time: 5.95 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvdLF7jjREuv",
        "outputId": "60f21e27-477a-4f37-e65c-484a0fc24fa4"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat May  1 05:10:18 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL6-XP7zzH7h",
        "outputId": "feea5e99-c146-4082-d9bd-2bf0d8fa0333"
      },
      "source": [
        "import os\n",
        "import io\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import zipfile\n",
        "import random\n",
        "import time\n",
        "import csv\n",
        "import datetime\n",
        "from itertools import compress\n",
        "from collections import Counter, defaultdict\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from transformers import AutoTokenizer, AutoConfig, AutoModelForPreTraining, \\\n",
        "                         AdamW, get_linear_schedule_with_warmup, \\\n",
        "                         TrainingArguments, BeamScorer, Trainer\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, random_split, DataLoader, \\\n",
        "                             RandomSampler, SequentialSampler\n",
        "\n",
        "from IPython.display import clear_output\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch version: 1.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEifVG4niJtC",
        "outputId": "6084f150-5b3d-4907-d169-c18455f11be3"
      },
      "source": [
        "\n",
        "import io, os, sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import zipfile\n",
        "import time\n",
        "import csv\n",
        "import re\n",
        "import multiprocessing\n",
        "from multiprocessing import Pool\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Zs_sffMF_Sw"
      },
      "source": [
        "!pip install kaggle\n",
        "!pip uninstall -y kaggle\n",
        "!pip install --upgrade pip\n",
        "!pip install kaggle==1.5.12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpiTkPyQBGLB"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwZNChSjhv9T"
      },
      "source": [
        "!kaggle competitions download -c dl-hack-track-2-nlp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Omhg-4vh3pI"
      },
      "source": [
        "!unzip /content/dl-hack-track-2-nlp.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3cl-bSrj1hD"
      },
      "source": [
        "!python -m spacy download en_core_web_lg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZDy9RClRiQ3"
      },
      "source": [
        "### Configurations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QILzrXuoRhaF"
      },
      "source": [
        "DEBUG           = False\n",
        "\n",
        "USE_APEX        = True\n",
        "APEX_OPT_LEVEL  = 'O1'\n",
        "\n",
        "MODEL           = 'gpt2' #{gpt2, gpt2-medium, gpt2-large, gpt2-xl}\n",
        "\n",
        "UNFREEZE_LAST_N = 6 #The last N layers to unfreeze for training\n",
        "\n",
        "SPECIAL_TOKENS  = { \"bos_token\": \"<|BOS|>\",\n",
        "                    \"eos_token\": \"<|EOS|>\",\n",
        "                    \"unk_token\": \"<|UNK|>\",                    \n",
        "                    \"pad_token\": \"<|PAD|>\",\n",
        "                    \"sep_token\": \"<|SEP|>\"}\n",
        "                    \n",
        "MAXLEN          = 768  #{768, 1024, 1280, 1600}\n",
        "\n",
        "TRAIN_SIZE      = 0.8\n",
        "\n",
        "if USE_APEX:\n",
        "    TRAIN_BATCHSIZE = 4\n",
        "    BATCH_UPDATE    = 16\n",
        "else:\n",
        "    TRAIN_BATCHSIZE = 2\n",
        "    BATCH_UPDATE    = 32\n",
        "\n",
        "EPOCHS          = 4\n",
        "LR              = 5e-4\n",
        "EPS             = 1e-8\n",
        "WARMUP_STEPS    = 1e2\n",
        "\n",
        "SEED            = 2020"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "740ZIyZXRbWe"
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(SEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RpxktDOHpMI"
      },
      "source": [
        "### Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "tsFp19NmHv64",
        "outputId": "1608bf41-38d0-43a5-d34f-6884e2dabafb"
      },
      "source": [
        "columns = ['title', 'text']\n",
        "\n",
        "df = pd.read_csv(\"train.csv\", index_col = None, header = 0, names= columns )\n",
        "print(f\"df size: {len(df) :,}\")\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df size: 146,381\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Interpretation of 3D CNNs for Brain MRI Data C...</td>\n",
              "      <td>Deep learning shows high potential for many ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Scientific Calculator for Designing Trojan Det...</td>\n",
              "      <td>This work presents a web-based interactive n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Proposal Flow</td>\n",
              "      <td>Finding image correspondences remains a chal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cloud-based or On-device: An Empirical Study o...</td>\n",
              "      <td>Modern mobile applications are benefiting si...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Retrofitting Structure-aware Transformer Langu...</td>\n",
              "      <td>We consider retrofitting structure-aware Tra...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title                                               text\n",
              "0  Interpretation of 3D CNNs for Brain MRI Data C...    Deep learning shows high potential for many ...\n",
              "1  Scientific Calculator for Designing Trojan Det...    This work presents a web-based interactive n...\n",
              "2                                      Proposal Flow    Finding image correspondences remains a chal...\n",
              "3  Cloud-based or On-device: An Empirical Study o...    Modern mobile applications are benefiting si...\n",
              "4  Retrofitting Structure-aware Transformer Langu...    We consider retrofitting structure-aware Tra..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0xL7sOxELJ3"
      },
      "source": [
        "data = dict()\n",
        "for id in range(len(df)):\n",
        "\n",
        "  data[id] = [df.title[id], df.text[id]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdLZSQ2uFeJh",
        "outputId": "bc8a1ce9-8496-4dfc-b9da-bfb8e575d66f"
      },
      "source": [
        "data[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Scientific Calculator for Designing Trojan Detectors in Neural Networks',\n",
              " '  This work presents a web-based interactive neural network (NN) calculator and a NN inefficiency measurement that has been investigated for the purpose of detecting trojans embedded in NN models. This NN Calculator is designed on top of TensorFlow Playground with in-memory storage of data and NN graphs plus coefficients. It is \"like a scientific calculator\" with analytical, visualization, and output operations performed on training datasets and NN architectures. The prototype is aaccessible at https://pages.nist.gov/nn-calculator. The analytical capabilities include a novel measurement of NN inefficiency using modified Kullback-Liebler (KL) divergence applied to histograms of NN model states, as well as a quantification of the sensitivity to variables related to data and NNs. Both NN Calculator and KL divergence are used to devise a trojan detector approach for a variety of trojan embeddings. Experimental results document desirable properties of the KL divergence measurement with respect to NN architectures and dataset perturbations, as well as inferences about embedded trojans. ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2j0V83HbH6QF"
      },
      "source": [
        "### Datasets and loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8gp0I8JnMEE"
      },
      "source": [
        "class myDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, tokenizer, randomize=True):\n",
        "\n",
        "        title, text = [], []\n",
        "        for k, v in data.items():\n",
        "            title.append(v[0])\n",
        "            text.append(v[1])\n",
        "\n",
        "        self.randomize = randomize\n",
        "        self.tokenizer = tokenizer \n",
        "        self.title     = title\n",
        "        self.text      = text\n",
        "\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "\n",
        "    \n",
        "    def __getitem__(self, i):\n",
        "        '''keywords = self.keywords[i].copy()\n",
        "        kw = self.join_keywords(keywords, self.randomize)'''\n",
        "        \n",
        "        input = SPECIAL_TOKENS['bos_token'] + self.title[i] + \\\n",
        "                SPECIAL_TOKENS['sep_token'] + SPECIAL_TOKENS['sep_token'] + \\\n",
        "                self.text[i] + SPECIAL_TOKENS['eos_token']\n",
        "\n",
        "        encodings_dict = tokenizer(input,                                   \n",
        "                                   truncation=True, \n",
        "                                   max_length=MAXLEN, \n",
        "                                   padding=\"max_length\")   \n",
        "        \n",
        "        input_ids = encodings_dict['input_ids']\n",
        "        attention_mask = encodings_dict['attention_mask']\n",
        "        \n",
        "        return {'label': torch.tensor(input_ids),\n",
        "                'input_ids': torch.tensor(input_ids), \n",
        "                'attention_mask': torch.tensor(attention_mask)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwCXZgyrU7P5"
      },
      "source": [
        "def split_data(data, S=TRAIN_SIZE):\n",
        "    # Shuffle ids\n",
        "    ids = list(data.keys())\n",
        "    random.shuffle(ids)\n",
        "\n",
        "    # Split into training and validation sets    \n",
        "    train_size = int(S * len(data))\n",
        "\n",
        "    train_ids = ids[:train_size]\n",
        "    val_ids = ids[train_size:]\n",
        "\n",
        "    train_data = dict()\n",
        "    for id in train_ids:\n",
        "        train_data[id] = data[id]\n",
        "\n",
        "    val_data = dict()\n",
        "    for id in val_ids:\n",
        "        val_data[id] = data[id]\n",
        "\n",
        "    return train_data, val_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3LfEbc5j9Yo"
      },
      "source": [
        "### Loading Tokenizer, Config and Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knL24TEIX9fl"
      },
      "source": [
        "def get_tokenier(special_tokens=None):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL) #GPT2Tokenizer\n",
        "\n",
        "    if special_tokens:\n",
        "        tokenizer.add_special_tokens(special_tokens)\n",
        "        print(\"Special tokens added\")\n",
        "    return tokenizer\n",
        "\n",
        "def get_model(tokenizer, special_tokens=None, load_model_path='/content/gdrive/MyDrive/pytorch_model_2.bin/pytorch_model.bin'):\n",
        "\n",
        "    #GPT2LMHeadModel\n",
        "    if special_tokens:\n",
        "        config = AutoConfig.from_pretrained(MODEL, \n",
        "                                            bos_token_id=tokenizer.bos_token_id,\n",
        "                                            eos_token_id=tokenizer.eos_token_id,\n",
        "                                            sep_token_id=tokenizer.sep_token_id,\n",
        "                                            pad_token_id=tokenizer.pad_token_id,\n",
        "                                            output_hidden_states=False)\n",
        "    else: \n",
        "        config = AutoConfig.from_pretrained(MODEL,                                     \n",
        "                                            pad_token_id=tokenizer.eos_token_id,\n",
        "                                            output_hidden_states=False)    \n",
        "\n",
        "    #----------------------------------------------------------------#\n",
        "    model = AutoModelForPreTraining.from_pretrained(MODEL, config=config)\n",
        "\n",
        "    if special_tokens:\n",
        "        #Special tokens added, model needs to be resized accordingly\n",
        "        model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "    if load_model_path:\n",
        "        model.load_state_dict(torch.load(load_model_path))\n",
        "\n",
        "    model.cuda()\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2zrELuFTzEG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306,
          "referenced_widgets": [
            "9c5e0804cb9b473e89c91b359f0011db",
            "4fa802271d304e3fa614632775ed525e",
            "dff126491e7346cbbf4d18342507e120",
            "da06e8cb1ade4df1bfb2eb2995e38e3e",
            "c8f5c46185734d0c958473375d94627e",
            "dbb5c284e3de4ccfa33d6f1cb99d946f",
            "d57e653cc7d241b6964fbe989ffa18ed",
            "338d059d5ab3441c9473c45126af20d8",
            "731653a4f85642f0ae327e82a52c8fe1",
            "80a473331aaf4ffe8408de10199d66bd",
            "f6965a40dcd4436e817353a60f1a2634",
            "921e29fff60749f1863a0e15cb2f641b",
            "79b6fca8ae6a491787d5c4831a7a8fd0",
            "2784d9076df84fb8bcdf9ccaa0006002",
            "44bbaf8ed01e491590071dc672dabd59",
            "61df7bbec4104f5a834ba7908365d450",
            "58f398457e2a49028b746d2a0d64edbb",
            "d8ebe772fa22404ea9dcbb6f9f9acace",
            "82d6217b4a2d41c68a908e8ece3989f4",
            "e1d7741765b240158f4a7db20cf97ffb",
            "b418411dac42484fb337066b4d08c284",
            "5a2c0c506c904745a832f66065071267",
            "41662164888d43fa97db2e2c16768716",
            "a43f1849597c48968d197eb4c56c7bf6",
            "d1d7fcc6fac943d3875fe40af6ee8752",
            "e90d7967ba11430daab0c8c53acd932f",
            "0402843310504b6e9979187c8da88fef",
            "8e4eaf93b91342c48f74d2a4d8771f70",
            "fa78f5fefa9a452a957055a9adf074e7",
            "a9575371c8394b8586b3a69ae4d81ce5",
            "9b2a17e209a8400c855a6dd26d354ae4",
            "1ad35862b38e466299c793cb3f884490",
            "bf52ac19acea4364b11a06e98cf57759",
            "3b2b89b308b7466180cb8f2a7ec5fc33",
            "0bccf6c3334748bbbe144b644877b7b2",
            "2e8e788616114661b60af2b03b60cf61",
            "98dd5b3c5ca24ae3bd309072af0d4f1f",
            "40b8d871ad084c129c9ee8ed9f8b2591",
            "a1f177e8aa24408a8cc9d1fe40d81132",
            "a97962f638054388b653d1e30b58673a"
          ]
        },
        "outputId": "d5d3b824-2b67-43be-f466-4fd13adb860e"
      },
      "source": [
        "%%time\n",
        "\n",
        "tokenizer = get_tokenier(special_tokens=SPECIAL_TOKENS)\n",
        "model = get_model(tokenizer, \n",
        "                  special_tokens=SPECIAL_TOKENS,\n",
        "                #   load_model_path='pytorch_model.bin'\n",
        "                 )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c5e0804cb9b473e89c91b359f0011db",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=665.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "731653a4f85642f0ae327e82a52c8fe1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1042301.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58f398457e2a49028b746d2a0d64edbb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d1d7fcc6fac943d3875fe40af6ee8752",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355256.0, style=ProgressStyle(descript…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Special tokens added\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf52ac19acea4364b11a06e98cf57759",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=548118077.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CPU times: user 17.2 s, sys: 3.54 s, total: 20.8 s\n",
            "Wall time: 43.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iGa-FRWAzWI"
      },
      "source": [
        "# - Freeze selective layers:\n",
        "# - Freeze all layers except last n:\n",
        "for parameter in model.parameters():\n",
        "    parameter.requires_grad = False\n",
        "\n",
        "for i, m in enumerate(model.transformer.h):        \n",
        "    #Only un-freeze the last n transformer blocks\n",
        "    if i+1 > 12 - UNFREEZE_LAST_N:\n",
        "        for parameter in m.parameters():\n",
        "            parameter.requires_grad = True \n",
        "\n",
        "for parameter in model.transformer.ln_f.parameters():        \n",
        "    parameter.requires_grad = True\n",
        "\n",
        "for parameter in model.lm_head.parameters():        \n",
        "    parameter.requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHYTARXZOKwP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "258aa9f1-5860-45bd-e0c2-b5cfb34b86c0"
      },
      "source": [
        "train_data, val_data = split_data(data)\n",
        "\n",
        "train_dataset = myDataset(train_data, tokenizer)\n",
        "val_dataset = myDataset(val_data, tokenizer, randomize=False)\n",
        "\n",
        "f'There are {len(train_dataset) :,} samples for training, and {len(val_dataset) :,} samples for validation testing'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'There are 117,104 samples for training, and 29,277 samples for validation testing'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYh9gAM_lAxK"
      },
      "source": [
        "### Fine-tune GPT2 using Trainer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsKQJis8jcCh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "01b810e7-c037-46c4-e153-1d670745ce84"
      },
      "source": [
        "%%time\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/\",\n",
        "    num_train_epochs=0.5,\n",
        "    per_device_train_batch_size=TRAIN_BATCHSIZE,\n",
        "    per_device_eval_batch_size=TRAIN_BATCHSIZE,\n",
        "    gradient_accumulation_steps=BATCH_UPDATE,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    fp16=True,\n",
        "    fp16_opt_level=APEX_OPT_LEVEL,\n",
        "    warmup_steps=WARMUP_STEPS,    \n",
        "    learning_rate=LR,\n",
        "    adam_epsilon=EPS,\n",
        "    weight_decay=0.01,        \n",
        "    save_total_limit=1,\n",
        "    load_best_model_at_end=True,     \n",
        ")\n",
        "\n",
        "#---------------------------------------------------#\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,    \n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "#---------------------------------------------------#\n",
        "trainer.train()\n",
        "trainer.save_model()    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='915' max='915' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [915/915 3:12:23, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Samples Per Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.844500</td>\n",
              "      <td>0.853542</td>\n",
              "      <td>2877.299200</td>\n",
              "      <td>10.175000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3h 52min 33s, sys: 2h 16min 19s, total: 6h 8min 52s\n",
            "Wall time: 3h 12min 35s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOZfqY118oe8"
      },
      "source": [
        "model.save_pretrained('pytorch_model_2.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYvCYf-zfs7V"
      },
      "source": [
        "# Save to G-Drive ----------------------------------#\n",
        "!cp -r 'pytorch_model_2.bin' '/content/gdrive/MyDrive'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0azvVPXCx4eM"
      },
      "source": [
        "### Generating text with Fine-tuned GPT-2 model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM39_zQLhiZw"
      },
      "source": [
        " !cp -r '/content/gdrive/pytorch_model_V2.bin' 'pytorch_model.bin' "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dojGngEDRupX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f832c35-8581-410c-ce11-b58bd332dab9"
      },
      "source": [
        "tokenizer = get_tokenier(special_tokens=SPECIAL_TOKENS)\n",
        "model = get_model(tokenizer, \n",
        "                  special_tokens=SPECIAL_TOKENS,\n",
        "                  #load_model_path='/content/pytorch_model.bin/pytorch_model.bin'\n",
        "                  )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Special tokens added\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYCC-ugJJy3A"
      },
      "source": [
        "title = \"Scientific Calculator for Designing Trojan Detectors in Neural Networks\"\n",
        "#keywords = ['train', 'lads', 'drinking', 'picture', 'funny', 'instagram']\n",
        "#kw = myDataset.join_keywords(keywords, randomize=False)\n",
        "\n",
        "prompt = SPECIAL_TOKENS['bos_token'] + title + \\\n",
        "         SPECIAL_TOKENS['sep_token'] + SPECIAL_TOKENS['sep_token']\n",
        "         \n",
        "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "device = torch.device(\"cuda\")\n",
        "generated = generated.to(device)\n",
        "\n",
        "model.eval();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gr02oxpsVXlM",
        "outputId": "cbc11388-fa5d-4c6c-b863-f1f92609892b"
      },
      "source": [
        "data[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Scientific Calculator for Designing Trojan Detectors in Neural Networks',\n",
              " '  This work presents a web-based interactive neural network (NN) calculator and a NN inefficiency measurement that has been investigated for the purpose of detecting trojans embedded in NN models. This NN Calculator is designed on top of TensorFlow Playground with in-memory storage of data and NN graphs plus coefficients. It is \"like a scientific calculator\" with analytical, visualization, and output operations performed on training datasets and NN architectures. The prototype is aaccessible at https://pages.nist.gov/nn-calculator. The analytical capabilities include a novel measurement of NN inefficiency using modified Kullback-Liebler (KL) divergence applied to histograms of NN model states, as well as a quantification of the sensitivity to variables related to data and NNs. Both NN Calculator and KL divergence are used to devise a trojan detector approach for a variety of trojan embeddings. Experimental results document desirable properties of the KL divergence measurement with respect to NN architectures and dataset perturbations, as well as inferences about embedded trojans. ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1gM2DvGeh2i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24b79057-be53-4104-fbbd-ed561baf15cc"
      },
      "source": [
        "# Top-p (nucleus) text generation (10 samples):\n",
        "sample_outputs = model.generate(generated, \n",
        "                                do_sample=True,   \n",
        "                                min_length=50, \n",
        "                                max_length=MAXLEN,\n",
        "                                top_k=30,                                 \n",
        "                                top_p=0.7,        \n",
        "                                temperature=0.9,\n",
        "                                repetition_penalty=2.0,\n",
        "                                num_return_sequences=10\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "    text = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
        "    a = len(title) \n",
        "    print(\"{}: {}\\n\\n\".format(i+1,  text[a:]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1:   The paper describes a new mathematical model that allows to calculate the probability of detecting an unknown program by analyzing its parameters. In this approach, we propose three novel algorithms: (i) Linear Programming and Evolutionary Algorithms; their computational complexity is proportional with respect {1/2} {\\log(T)} times \\sqrt{N})$, which are more efficient than other machine learning techniques on binary classification problems but not necessarily as accurate or faster compared against standard methods suchas Random Forest-based classifiers when applied within linear programming frameworks like BERT. We also provide empirical evidence showing how these approaches can be used successfully both inside neural networks trained using backpropagation based models while avoiding some known weaknesses present during training procedures from conventional ones - eigenspace, overfitting etc.; they may lead us towards better solutions if further improvements need being made before deployment via deep reinforcement Learning systems without compromising accuracy at test time due~to existing data collection strategies employed heretically? Our experiments indicate significant improvement upon previous stateofthe art implementations including DNNs implemented directly through gradient descent schemes whereas our results suggest promising future research directions beyond artificial intelligence design issues regarding generalization capabilities arising out therefrom rather well documented elsewhere so far into current software engineering processes across many domains where similar challenges exist only recently under development yet remain largely unsolved despite extensive theoretical investigation about algorithmic properties related either internal space structure characteristics nor any inherent differences between them themselves -- hence providing additional insights leading toward improved AI designs targeting real world applications whose goals require robustness whilst remaining computationally cheap relative otherwise expensive alternatives available justifiably scarce resources today's NLP libraries rely heavily onto GPU memory and thus have been shown potentially impractical outside those aforementioned areas since most practitioners use CPU accelerators instead.. Finally, it was demonstrated empirically what would happen to modern software systems if researchers started investing effort investigating alternative architectures capable enough efficiently solving various computer vision tasks even though no progress has ever taken place until now because all involved work had already begun after the publication [1]. This article provides one possible explanation behind why such ideas might prove useful especially for developing advanced Artificial Intelligence systems specifically tailored around black box attacks requiring highly specialized hardware and compute nodes operating entirely autonomously locally distributed computing infrastructure... \n",
            "\n",
            "\n",
            "2:   In this paper, we present a scientific calculator to help users find the best algorithm that will be able and efficient on their neural network architectures. This is an open source library with Python 3 compatible implementations of many popular deep learning models such as AlexNet or VGG-16xlarge model by using it freely available from PyPi GitHub repository at https://github.,https\\url{www}. We also provide some guidelines related towards designing better Trojan detection algorithms based upon these ideas: 1) Use different training methods (different number schemes), 2)- Increase computational efficiency through increasing parallelism; 4-) The combination between machine reading speedup/optimization can boost accuracy over other approaches when used together within our libraries without compromising performance quality metrics like F1 score / PflopScore). Our results demonstrate both advantages vs compared alternatives among state agnostic learners including those trained only under certain conditions but not all tested systems are created equally well so there might exist situations where one could use several types' techniques during testing time while maintaining high prediction accuracies especially if they were implemented separately into multiple frameworks insteadof directly running them independently due reasons i}trolling each system to make predictions before deployment etc.; 5+ - Open Source code allows easy customization options via simple editing procedures which allow us flexible ways how much of data space should remain allocated according its specific nature \\citeas http :~yunzhangkengu8w.org. Code made publicly available online provides more detailed details about various components involved regarding implementation choices across three commonly cited NLP tasks ranging up till now being relatively small workflows along side extensive experimentation done manually inside python projects provided easily accessible software packages and web interfaces required respectively.(http): www..nocompromisespytorch_datatonsignalgisturepipeline2solutionsisystemiadjunctioneplaptionetworkflowverdeformenantividensselldertempericallanguagesbankstochnicaarbeit.com/. For example please visit http:(href=site url)(http:\"https://codehublabelsearchcenter\".googleusercontent.). \n",
            "\n",
            "\n",
            "3:   The proliferation of neural networks has led to an increasing demand on security-critical applications. However, the performance and efficiency are still far from satisfactory with respect not only traditional models but also deep learning techniques such as adversarial training or kernel methods (which have been shown successful at solving various computer vision tasks). In this paper we present a novel approach that combines multiple different approaches: machine intelligence based algorithm design/exploitation technique through evolutionary algorithms; data mining method by combining model selection using ensemble boosting procedure followed via Bayesian optimization process over large number matrix approximations used within each classifier network architecture - which is capable enough when applied effectively against modern attack systems like Google's Adversarially Robust Classifiers~(AN) framework due both its robustness capability towards nonlinear attacks during inference time versus accuracy under arbitrary input perturbation regimes compared without any prior knowledge about classification properties nor loss function parameters required across all datasets being explored simultaneously since they share similar features between classes while having comparable computational complexity per iteration regardless if there exists one type available among other types employed separately? We propose two new variants designed specifically targeting these challenges along several aspects including dimensionality reduction associated standard deviation error analysis methodology whilst retaining their theoretical guarantees despite lacking some specificity assumptions concerning what may be achievable even after adding noise into them beyond normal range ranges so called \"noise\". For evaluation purposes our proposed solutions were evaluated extensively empirically comparing existing stateoftheart defense strategies amongst those found most suitable according TOA criteria tested throughout four real world application scenarios ranging up till now spanning six years before deployment onto public platforms where it was proven very challenging otherwise known architectures would fail catastrophistically once deployed upon detection capabilities waned considerably.. To further validate effectiveness results presented herein suggest promising directions forward regarding future research opportunities pertaining toward designing sophisticated defensive malware detectors operating solely inside OFAs implemented therein! A detailed description can then easily serve potential researchers interested working directly alongside us who want more thorough explanations why these works should benefit society \n",
            "\n",
            "\n",
            "4:   The use of deep learning techniques to improve the performance and robustness on a variety applications has led researchers from both academia, industry-leading companies as well research communities. However most stateful solutions that are developed using machinelearning algorithms do not scale very accurately due mainly their scalability issues; moreover many practical implementation is not possible or expensive even when it comes with limited data available at test time (eXploration). In this paper we propose an automated system based around our recent work \"Optimal design technique\" which can solve these problems effectively by utilizing different features extracted automatically through Deep Learning approaches suchas Adaptive Optimization Algorithm(AOA) framework over various optimization tasks including image classification problem: An analysis against two widely used neural network models shows promising results comparedwith other methods like AdaBoost/LDA++ algorithm. It also demonstrates its effectiveness if additional training samples have been provided insteadof only one sample per classifier model but otherwise achieves good accuracy under certain conditions especially high computational cost without losing much information about original feature extraction process.. We show how AO will help us reduce complexity caused issue among some popular existing works' implementations while providing better interpretable explanations behind them via empirical studies conducted during testing phase i - e., they demonstrate significant improvementsover current published frameworks accordingto several numerical tests performed across six benchmark datasets containing four real world application domains rangingfrom artificial intelligence detection systems development pipeline, bioinformatics domain where there exist multiple typesOf Artificial Intelligence Detection System~($\\text{ATS}}_0$), drug discovery field called Drug Discovery Problem ($ \\approx 20^{3}^4})and medical diagnosis platform $DDSP$, showing great potentialsamong others within each specific scenario thus proving new insights into designing intelligent malware detectorsfor general purpose deployment needs between nowhere far away}. Code & preprocessing code should be made publicly accessible so anyone who wantsTo contribute any further knowledge regarding those aforementioned challenges may contact our project page : https://githubganalyaevanovabahari@googlemailbox2/. This article aims towards helping practitioners develop effective decision support tools ableespecially suitable toolkits related technologies tailored specifically suited toward security sensitive computer vision area since today's Internet technology brings more opportunities than ever before concerning safety awareness along all kinds aspects regardlessofthe software level being takencarefully designed efficiently enoughby developers.(*) For reproducibility of experiments run here please see http:\\wwwspaceprogrammingresearchgroupai2019iidrvadakumarattegioruetengirajitrajainenpargesteagradhanikaramurthyyaapuriwongshohaneerudhavnadiiparamacharyadaonchitnispradeshrammohanathankumaranshubertshebaesalmannayaachenikshiyanthayukrishnanathayekhaisimaniyurujiannagridharithuwanthanvirajanishkaadeesanneelgariajasonjakshedmihtoriqvihaarwardejantapellagrajasthaarameswarangarojaanmalanganzhaochanningharaojharivankevinpalavaizhouxingjunthammenachorussianparsimoniouslyuttaanjunwangulyanyanbalajiisonaigunnaegulaikshasivashisharmaarthritis palauchi kevalryasseetaiboskarami jasinasutraanjainanjunthammenaisalguptaahani sambodni sangharekhanaoichi suntilu serensaibi steveinuwanmuaritaiguh\n",
            "\n",
            "\n",
            "5:   This paper presents the first scientific calculator to help users select and tune their machine learning algorithms. The proposed calculi are designed using an open source Python package called PyTorch, which is available from https://githublabels/pytorch-tools. Users can download it at: http:\\url{https\\_e}lj/pypyrorch/. To find out if a user needs assistance with finding his own algorithmic tool or algorithm (or other software), we use this Python library as our scientific advisor that allows anyone wishing on finding a suitable method of automated search by automatically selecting appropriate hyperparameters based upon input data points extracted through numerical analysis techniques suchAs a proof technique used against several popular black box attacks like adversarial examples generated via random forests during training time; another one uses gradient descent methods insteadof backpropagation due either because they have higher computational complexity than traditional optimization schemes when compared over different architectures); furthermorewe provide experimental results showing how well these classifiers perform across multiple datasets where each dataset has been trained independently but not both manually nor individually so far without any prior knowledge about them before making decisions towards deployment.. These classesifier settings also allow us easily extend existing models into new ones including deep neural networks - especially those obtained under specific conditions regarding hardware limitations). Our implementation makes full use only part preprocessing steps needed within modern computing systems since no need will be made otherwise although some additional modifications may require further research effort while ensuring reproducibility throughout future workflows along side providing the flexibility required whilst maintaining high accuracy beyond what would normally happen herewith.(The codebase files provided below contain all necessary documentation and scripts)This article contains references related papers written between January 2010--January 2020 concerning various kindsOf implementations presented together amongst others included in pyrarch(http):On top thereof we present tools built specificallyfor identifying malware targeting NLP applications given binaries found inside Google's Cloud API repository hosted alongside web pages for developers interestedin creating security solutions aimedat helping practitioners navigate around vulnerabilities associatedto malicious apps... \n",
            "\n",
            "\n",
            "6:   In this paper, we propose a new methodology that combines statistical and machine learning techniques to construct an accurate mathematical model of neural networks. We introduce the notion \"designer\" as part-of--the---future paradigm which provides solutions at every iteration without requiring any prior knowledge about their architecture or hardware design parameters during training time (e., no need with hyperparameters). The proposed method is able simultaneously predict whether certain input data points will be attacked by different types/attacks using only one classifier trained on them; thus making it possible even when all known inputs are used throughout test execution phase so far its performance can significantly improve over traditional methods like SVM [1]. Furthermore our approach has several advantages: 1) It does not require handcrafted features nor requires many iterations required due both nature - computational efficiency reduction while maintaining accuracy within reasonable range bounds 2), unlike other approaches such Asynchronous Optimization based algorithms may result from high probability models' optimization process rather than directly relying upon gradient descent heuristics 3); moreover these results show promise compared against existing state space optimizers but also provide strong theoretical guarantees concerning how well they perform across various architectures under varying threat scenarios including adversarial examples posed through attack propagation attacks 4.) Our work shows promising prospects towards building robust systems capable effectively defend artificial intelligence applications beyond those currently available via deep reinforcement Learning(RL)-based security mechanisms[2]. More importantly, if researchers have confidence regarding predictive power levels necessary beforehand then perhaps designing efficient algorithms would benefit greatly since current implementations tend either lack practical experience achieving real world deployment or fail catastrophically because too much effort was spent searching blindly into black box models instead having actual intuition behind why something might actually do wrong... This study suggests future research directions where practitioners should carefully consider what kind~concepts could potentially help them achieve success once presented together before human decision makers become overwhelmed.. Finally some open questions pertaining further developments related specifically include potential implications around algorithmic innovations impacting AI capabilities & safety requirements? Code made publicly Available At https://github.}https{www}.com/jamesy/sciencecalculator_forgiorgi \n",
            "\n",
            "\n",
            "7:   This paper presents a practical design of an effective and accurate neural network model that can be used to predict the success or failure probability (success rate) given input data. Our algorithm is based on learning from real-world datasets with various combinations including, but not limited only: 1D convolutional layers; 3x3 kernels trained by LSTM networks as well Asynchronous backpropagation techniques suchas batch normalization are utilized which allows us more flexibility than previous methods due also being able utilize different typesof hardware platforms like GPUs/CUDA accelerators For this purpose we develop novel architectures using our newly developed architecture called \"scientific calculator\". It consists within two stages - firstly it uses some kind function approximator designed specifically according TOBADAS. Secondly through calculating all possible values needed during training process while keeping their accuracy close enough at 99% correctness level so far even though these calculations may lead one into wrong conclusions about how good they were originally predicted By combining multiple kinds OF computing devices AND memory resources the proposed system has shown excellent performance against several popular deep models without any loss compared With respect both theoretical guarantees i1bfinite time solution bound when applied over conventional linear algebraic optimization scheme iiibouti random matrix solver. The code will open source at https://github.}viiitlabuetmakulenkurutinachenikonatigtetnokutektaensaerkulutisemteiertelmanekutolutisomapaksiventet \n",
            "\n",
            "\n",
            "8:   The development of the Artificial Intelligence (AI) field has allowed to develop intelligent, efficient and robust cyber-physical systems. In this paper we present a novel method that uses deep learning techniques on artificial intelligence as an alternative tool when designing security mechanisms such malware detection algorithms or attacks against neural networks based classifiers using standard machine reading tools like Machine Learning methods with respect not only their accuracy but also efficiency which is crucial since it allows us design new vulnerabilities without any human intervention by means thereof while keeping our system secure from malicious users who have access over time through intrusion into its functionality due online communication channels at home devices etc., making them susceptible both theoretically ($\\text{https://github3dresearch/scpell_attack}$). We show how simple numerical solutions can be found even if they are designed carefully enough so these schemes may lead easily adversaries towards sophisticated attack functions targeting network traffic monitoring applications where one cannot easily find all possible vulnerabilities within seconds given limited data size $ \\mathcal {T}}$. These results demonstrate stateofthe art performance improvements obtained compared either manually created random perturbations generated randomly $\\approx 10^{100}\\times 100$, including some commonly used ones; however there were no previously known implementations available under suitable assumptions regarding what kind adversarial examples could fool modern models trained specifically around those features? Furthermore many other factors related directly between different threat domains should play important roles: i.) whether each adversary will use small amounts $(1+n)\\leq 1 - k(k))$$'s input vectors per example instead because none exists yet), ii.}') whose output vector contains more than half probability measures about every single point being chosen correctly; iii.; iv.). Thus far most current research focus primarily focused solely upon defense strategies employed during training phase involving specific architectures proposed recently -- mainly defensive approaches like gradient boosting followed via randomized thresholded search, adaptive threshold value selection along side normalization combined together amongst others--and did little work investigating generalizable threats arising out across various tasks required throughout AI community platforms alike eeCommerce products.. This article provides comprehensive evidence demonstrating several key insights gleanring useful knowledge beyond mere technical details concerning vulnerability level classification performed automatically inside NLP frameworks employing statistical analysis provided thereby providing valuable insight toward understanding why certain kindsOf attacks exist particularly well suited especially targeted IoT device detection technologies. Our code implementation includes open source software and preprocessing steps enabling researchers working exclusively outside academia interested further exploring this area. \n",
            "\n",
            "\n",
            "9:   The design of artificial intelligence (AI) systems that are able to detect and classify complex objects is a critical research problem. A major challenge, however: how do AI algorithms fit into the algorithmic workflow needed by real-world applications? In this paper we present an intelligent algorithm designed specifically with computer vision as its primary toolkit; it can generate novel visualizations using only human-generated data from different domains such networks or images captured on mobile devices at various scales -- making use more than one dimensionality reduction technique per object category while being capable enough not just generating visually plausible results but also providing high classification accuracy within reasonable time constraints without any user intervention required - even when there exist no training examples available during deployment phase. This approach provides significant flexibility over existing approaches which require large datasets collected via preprocessing methods including image processing techniques like JPEG compression/decomposition followed closely behind their original implementation because they allow them much higher speed compared against stateofthe art neural network classifiers trained solely through supervised learning processes rather then purely machine learned models based upon naturalistic features derived directly out front generated manually created labels instead known individually due either manual annotation errors arising outside our domain specific expertise nor model uncertainty caused since these deep generative adversarial perturbations were introduced backpropagated before publication itself onto actual samples given limited labeled ground truth information about individual instances across several dimensions ranging both geometric distance between classes / categories etc.; furthermore all prior knowledge concerning target properties has been incorporated explicitly along those axes so far allowing us further fine tune each layer's parameters beyond what was possible previously done otherwise where relevant yet informative statistics would be retained under appropriate circumstances thus significantly reducing computational cost associated towards future optimization efforts once used alone after deploying new architectures up until now\". Our method makes full applicationability accessible online and therefore allows users worldwide access whilst maintaining comparable performance regardless whether some form thereof exists publicly or privately provided \"in advance\" thereby opening doors toward developing AI solutions tailored exclusively suitable today if indeed desired.\" We show experimentally herewith two recent successes showing improved prediction accuracies obtained thanks largely combination effects stemming naturally off previous work by exploiting transferable structure learnt alongside other aspects proposed herein --- e., feature importance analysis---and demonstrate similar generalizabilities regarding recognition quality resulting improvements achieved despite having already seen substantial gains reported elsewhere related tasks involving automated detection tools developed around generic search engines whose main aim remains semantic similarity matching task defined mainly aiming primarily aimed precisely close similarities among pairs containing many distinct elements combined together enabling efficient experimentation amongst experts alike! More remarkably, none have shown explicit improvement whatsoever over traditional iteratively applied gradient boosting methods, despite achieving promising result rates almost identical irrespective requiring additional computing resources. These findings pave way forward attempts exploring potential ways ahead inspired especially recently presented Artificial Intelligence Systems & Techniques - a collection currently in development which aims well above standard metrics suggesting progress. To make senseOf course self employed automatic categorization capabilities should lead eventually understanding useful ideas comingfrom deep convolutional architecture design and could serve potentially vital role therein, as it helps push boundaries hitherto unexplored areas throughout software engineering pipelines leadingto meaningful insights pertainingforthcoming technologies, particularly the aforementioned fields... https://githubidocatvalu2019aac.git/pytorch \n",
            "\n",
            "\n",
            "10:   The design of deep learning models is often challenging. In this paper, we propose a new algorithm called Scientific calculator to solve the problem and demonstrate its efficiency by applying it on two tasks: classification-based malware detection with neural networks (NN) based attack vector detectors using an artificial intelligence approach that uses NNs as input feature vectors which can be used either directly or indirectly during training process; such method may lead one into incorrect predictions if they are incorrectly detected while being deployed at test time due TOA-v2 model which was originally designed from scratch but has been used extensively recently since December 2017 under different configurations like random forests/LSTMs etc.. For these reasons our proposed technique achieves promising results even when there were no available data samples containing maliciously crafted features nor without any realizable adversarial examples - thus making them suitable targets towards designing security mechanisms against Deep Learning systems attacks where those techniques do not exist yet~ This study also highlights some interesting research directions including developing novel defenses aimed specifically around obfuscating machine code so far developed within AI field through their potential application over existing ones via backdoored attacks applied only once after deployment before being removed completely. Our experiments show how accurate current defense methods perform better than stateofthe art alternatives considering both performance loss reduction factors along side accuracy gain compared waviness level respectively between original approaches whilst having high effectiveness rate across all datasets considered! We believe finding practical solutions should allow researchers working closely together aiming out ideas more effectively utilizing modern software tools rather then blindly focusing solely upon individual techniques employed independently instead choosing other advanced technology. Furthermore motivated mainly because recent work demonstrates similar success rates achieved despite significant differences among various algorithms utilized throughout development stages regarding system architectures required implementation space size, network topology requirements & hyperparameters resulting greatly boost overall predictive capability especially given large number generated features per layer requiring minimal hardware resources / communication overhead associated otherwise ~\\textit{research}~ \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAmwMuxa3xGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ce53416-5837-45de-f225-15c00266bfae"
      },
      "source": [
        "# Beam-search text generation:\n",
        "sample_outputs = model.generate(generated, \n",
        "                                do_sample=True,   \n",
        "                                max_length=MAXLEN,                                                      \n",
        "                                num_beams=5,\n",
        "                                repetition_penalty=5.0,\n",
        "                                early_stopping=True,      \n",
        "                                num_return_sequences=1\n",
        "                                )\n",
        "\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "    text = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
        "    a = len(title)\n",
        "    print(\"{}: {}\\n\\n\".format(i+1,  text[a:]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1:   In this paper, we propose a novel computer-aided design algorithm based on the Scientific Calculator (SCO) that can be used to automatically determine whether or not an attack has been launched. The SCO is composed of two components: 1) a multi-layer neural network and 2) a stochastic gradient descent method. Each component consists of three steps: first, it calculates the probability density function using Gaussian mixture models; second, it computes the mean squared error by computing the square root of the distance between the input training samples and the target model; and third, it extracts features from the test data via convolutional neural networks. Extensive experiments have been carried out with both synthetic and real adversarial examples. Experimental results show that the SCO significantly outperforms other state-of-the-art techniques such as DNNs and LSTMs when compared to existing methods. \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab83YP-T1DQ4"
      },
      "source": [
        "### Make predictions on test set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol_1K4aC-u9c"
      },
      "source": [
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "RZM2MXE4_rmE",
        "outputId": "f43fc02f-f210-4d69-9ee4-44418fc4f6b7"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Multi-factorial Optimization for Large-scale V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dialogue Act Classification with Context-Aware...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kernel Additive Principal Components</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sample Complexity of Learning Mixtures of Spar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Joint Coarse-And-Fine Reasoning for Deep Optic...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title\n",
              "0  Multi-factorial Optimization for Large-scale V...\n",
              "1  Dialogue Act Classification with Context-Aware...\n",
              "2               Kernel Additive Principal Components\n",
              "3  Sample Complexity of Learning Mixtures of Spar...\n",
              "4  Joint Coarse-And-Fine Reasoning for Deep Optic..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwUFPBUu_f_E"
      },
      "source": [
        "def generate(test):\n",
        "  output = []\n",
        "  i = 0\n",
        "  for title in test.title:\n",
        "  #keywords = ['train', 'lads', 'drinking', 'picture', 'funny', 'instagram']\n",
        "  #kw = myDataset.join_keywords(keywords, randomize=False)\n",
        "\n",
        "    prompt = SPECIAL_TOKENS['bos_token'] + title + \\\n",
        "          SPECIAL_TOKENS['sep_token'] + SPECIAL_TOKENS['sep_token']\n",
        "          \n",
        "    generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "    device = torch.device(\"cuda\")\n",
        "    generated = generated.to(device)\n",
        "\n",
        "\n",
        "    '''sample_outputs = model.generate(generated, \n",
        "                                    do_sample=True,   \n",
        "                                    max_length=MAXLEN,                                                      \n",
        "                                    num_beams=5,\n",
        "                                    repetition_penalty=5.0,\n",
        "                                    early_stopping=True,      \n",
        "                                    num_return_sequences=1\n",
        "                                    )'''\n",
        "    sample_outputs = model.generate(generated, \n",
        "                                do_sample=True,   \n",
        "                                min_length=50, \n",
        "                                max_length=MAXLEN,\n",
        "                                top_k=45,                                 \n",
        "                                top_p=0.7,        \n",
        "                                temperature=0.9,\n",
        "                                repetition_penalty=2.0,\n",
        "                                num_return_sequences=1\n",
        "                                )\n",
        "\n",
        "    #for i, sample_output in enumerate(sample_outputs):\n",
        "    text = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
        "    a = len(title)\n",
        "    out = \"{}\\n\\n\".format(text[a:])\n",
        "    output.append(out)\n",
        "    if i%100:\n",
        "      print('Done_'+ str(i))\n",
        "    i += 1\n",
        "  return output\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1gEsJdXJY_9"
      },
      "source": [
        "def generate_beam(test):\n",
        "  output = []\n",
        "  i = 0\n",
        "  for title in test.title:\n",
        "  #keywords = ['train', 'lads', 'drinking', 'picture', 'funny', 'instagram']\n",
        "  #kw = myDataset.join_keywords(keywords, randomize=False)\n",
        "\n",
        "    prompt = SPECIAL_TOKENS['bos_token'] + title + \\\n",
        "          SPECIAL_TOKENS['sep_token'] + SPECIAL_TOKENS['sep_token']\n",
        "          \n",
        "    generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
        "    device = torch.device(\"cuda\")\n",
        "    generated = generated.to(device)\n",
        "\n",
        "\n",
        "    sample_outputs = model.generate(generated, \n",
        "                                    do_sample=True,   \n",
        "                                    max_length=MAXLEN,                                                      \n",
        "                                    num_beams=5,\n",
        "                                    repetition_penalty=5.0,\n",
        "                                    early_stopping=True,      \n",
        "                                    num_return_sequences=1\n",
        "                                    )\n",
        "    '''sample_outputs = model.generate(generated, \n",
        "                                do_sample=True,   \n",
        "                                min_length=50, \n",
        "                                max_length=MAXLEN,\n",
        "                                top_k=30,                                 \n",
        "                                top_p=0.7,        \n",
        "                                temperature=0.9,\n",
        "                                repetition_penalty=2.0,\n",
        "                                num_return_sequences=10\n",
        "                                )'''\n",
        "\n",
        "    #for i, sample_output in enumerate(sample_outputs):\n",
        "    text = tokenizer.decode(sample_outputs[0], skip_special_tokens=True)\n",
        "    a = len(title)\n",
        "    out = \"{}\\n\\n\".format(text[a:])\n",
        "    output.append(out)\n",
        "    if i%100:\n",
        "      print('Done_'+ str(i))\n",
        "    i += 1\n",
        "  return output\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P38ErKisCOBE"
      },
      "source": [
        "output = generate(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AlnCwB6JhI5"
      },
      "source": [
        "output_1 = generate_beam(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPaFnWZvFPHj"
      },
      "source": [
        "dum = pd.DataFrame(output)\n",
        "dum.columns = ['abstract']\n",
        "df2 = pd.concat([test.title, dum.abstract], axis =1)\n",
        "df2.to_csv('submission.csv')\n",
        "!cp -r '/content/submission.csv' '/content/gdrive/MyDrive/submission.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "oYJSU6QJnLXZ",
        "outputId": "8378e9a6-c6fb-4a0c-978e-6b6f1398614a"
      },
      "source": [
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Multi-factorial Optimization for Large-scale V...</td>\n",
              "      <td>We study the problem of large scale virtual m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dialogue Act Classification with Context-Aware...</td>\n",
              "      <td>Dialogue act classification (CAS) is a cruci...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kernel Additive Principal Components</td>\n",
              "      <td>Kernel approximation is a fundamental techni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sample Complexity of Learning Mixtures of Spar...</td>\n",
              "      <td>We introduce a new formulation for learning ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Joint Coarse-And-Fine Reasoning for Deep Optic...</td>\n",
              "      <td>We present a new method to solve the problem...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title                                           abstract\n",
              "0  Multi-factorial Optimization for Large-scale V...   We study the problem of large scale virtual m...\n",
              "1  Dialogue Act Classification with Context-Aware...    Dialogue act classification (CAS) is a cruci...\n",
              "2               Kernel Additive Principal Components    Kernel approximation is a fundamental techni...\n",
              "3  Sample Complexity of Learning Mixtures of Spar...    We introduce a new formulation for learning ...\n",
              "4  Joint Coarse-And-Fine Reasoning for Deep Optic...    We present a new method to solve the problem..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6C642xiWMs-"
      },
      "source": [
        "import pandas as pd\n",
        "from typing import Dict, List\n",
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# DO NOT MODIFY\n",
        "pca = PCA(n_components=32)\n",
        "URL = \"https://model-apis.semanticscholar.org/specter/v1/invoke\"\n",
        "MAX_BATCH_SIZE = 16\n",
        "\n",
        "# split text into batches\n",
        "def chunkify(test_csv, chunk_size=MAX_BATCH_SIZE):\n",
        "    for i in range(0, len(test_csv), chunk_size):\n",
        "        chunk = []\n",
        "        for j in range(chunk_size):\n",
        "            indx = i+j\n",
        "            if indx == len(test_csv):\n",
        "                break\n",
        "            chunk.append(\n",
        "                {\n",
        "                    \"paper_id\": indx,\n",
        "                    \"title\": test_csv[\"title\"][indx],\n",
        "                    \"abstract\": test_csv[\"abstract\"][indx]\n",
        "                }\n",
        "            )\n",
        "        yield chunk\n",
        "def submit(test_csv):\n",
        "\n",
        "\n",
        "\n",
        "  test_csv = pd.read_csv(test_csv)\n",
        "  embeddings = []\n",
        "  cntr = 0\n",
        "  for chunk in chunkify(test_csv):\n",
        "      response = requests.post(URL, json=chunk)\n",
        "      if response.status_code != 200:\n",
        "          raise RuntimeError(\"Sorry, something went wrong, please try later!\")\n",
        "      for paper in response.json()[\"preds\"]:\n",
        "          embeddings.append(paper[\"embedding\"])\n",
        "          print(f\"[{cntr}/{len(test_csv)}]\", end=\"\\r\")\n",
        "          cntr += 1\n",
        "  print(\"Done... Creating submission file\")\n",
        "\n",
        "  embeddings = np.array(embeddings)\n",
        "  embeddings = pca.fit_transform(embeddings)\n",
        "  \n",
        "  df = pd.DataFrame.from_records(embeddings)\n",
        "  cols = {i: f\"f_{i}\" for i in range(32)}\n",
        "  df = df.rename(columns=cols)\n",
        "  df[\"id\"] = np.arange(len(embeddings))\n",
        "  df.to_csv(\"submission.csv\", index=False)\n",
        "  print(\"Submission file created at ./submission.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4R6AIXannxG",
        "outputId": "aa2503ca-a283-4099-b894-3763ad55c703"
      },
      "source": [
        "submit('submission.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done... Creating submission file\n",
            "Submission file created at ./submission.csv\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}